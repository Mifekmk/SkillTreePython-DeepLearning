{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ch01_07_CNN기초-Pooling_Layer.ipynb의 사본",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mifekmk/SkillTreePython-DeepLearning/blob/main/01.%EB%94%A5%EB%9F%AC%EB%8B%9Dwith%ED%85%90%EC%84%9C%ED%94%8C%EB%A1%9C%EC%9A%B0-basic/ch01_07_CNN%EA%B8%B0%EC%B4%88_Pooling_Layer_ipynb%EC%9D%98_%EC%82%AC%EB%B3%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ch01.07 CNN기초 - Pooling Layer\n",
        "---\n",
        "\n",
        "* 날짜: 2022-07-05\n",
        "* 이름: 김민규\n",
        "\n",
        "## 학습내용\n",
        "    - CNN의 개념을 이해한다.\n",
        "    - 텐서플로우를 이용해 CNN을 구성한다.\n",
        "    - CNN 모델을 이용해 손글씨 이미지를 분류한다.\n",
        "    - CNN의 feature map에 대해 이해한다.\n",
        "\n",
        "## 데이터셋\n",
        "\n",
        "* MNIST\n",
        "\n",
        "```\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "```"
      ],
      "metadata": {
        "id": "sWs2kEC1_b-P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "7vXrksNr0m1v"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pooling layer\n",
        "---\n",
        "\n",
        "풀링(Pooling) 연산은 커널과 스트라이드 개념이 존재한다는 점에서 합성곱 연산과 유사하지만, 학습해야 할 가중치가 없으며 연산 후에 채널 수가 변하지 않습니다. 일반적으로 합성곱 층(합성곱 연산 + 활성화 함수) 다음에는 풀링 층을 추가하는 것이 일반적입니다. \n"
      ],
      "metadata": {
        "id": "EL2T1tz6Y9yn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import MaxPool2D, AvgPool2D"
      ],
      "metadata": {
        "id": "gIW4t6tvstjV"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **| 맥스 풀링(Max Pooling)**\n",
        "맥스풀링은 이미지 영역의 최대값 만을 출력값으로 가지는 연산 방법입니다. \n",
        "\n",
        "\n",
        "\n",
        "<p align='center'>\n",
        "<img src=https://github.com/yebiny/SkillTreePython-DeepLearning/blob/main/imgs/ch0107-01.PNG?raw=true width=400>\n",
        "</p>\n",
        "\n"
      ],
      "metadata": {
        "id": "m3Y7QC2Lg_eo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.array([1,0,1,1,1,2,0,0,1,0,1,0,0,0,1,1], dtype='float16').reshape(1,4,4,1)\n",
        "print(x[0,:,:,0], x.shape) # kernel_size = pool_size input shape = (n.w, h, ch)\n",
        "y = MaxPool2D(pool_size=2, strides=1)(x)\n",
        "print(y[0,:,:,0], y.shape)"
      ],
      "metadata": {
        "id": "X3MbCf7Bk_yj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10c51c52-a625-45a7-e3b7-8f043c1f9743"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1. 0. 1. 1.]\n",
            " [1. 2. 0. 0.]\n",
            " [1. 0. 1. 0.]\n",
            " [0. 0. 1. 1.]] (1, 4, 4, 1)\n",
            "tf.Tensor(\n",
            "[[2. 2. 1.]\n",
            " [2. 2. 1.]\n",
            " [1. 1. 1.]], shape=(3, 3), dtype=float32) (1, 3, 3, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **| 평균 풀링(Average Pooling)**\n",
        "\n",
        "\n",
        "평균풀링은 이미지 영역의 평균값 을 출력값으로 가지는 연산 방법입니다. \n",
        "\n",
        "\n",
        "<p align='center'>\n",
        "<img src=https://github.com/yebiny/SkillTreePython-DeepLearning/blob/main/imgs/ch0107-02.PNG?raw=true width=400>\n",
        "</p>\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "qu4lThvGhun1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.array([1,0,1,1,1,2,0,0,1,0,1,0,0,0,1,1], dtype='float16').reshape(1,4,4,1)\n",
        "print(x[0,:,:,0], x.shape)\n",
        "y = AvgPool2D(pool_size=2, strides=1)(x)\n",
        "print(y[0,:,:,0], y.shape)"
      ],
      "metadata": {
        "id": "o1XirsZ5mqAY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7aebf1f-2d2a-4189-9a23-0c241e156679"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1. 0. 1. 1.]\n",
            " [1. 2. 0. 0.]\n",
            " [1. 0. 1. 0.]\n",
            " [0. 0. 1. 1.]] (1, 4, 4, 1)\n",
            "tf.Tensor(\n",
            "[[1.   0.75 0.5 ]\n",
            " [1.   0.75 0.25]\n",
            " [0.25 0.5  0.75]], shape=(3, 3), dtype=float32) (1, 3, 3, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LeNet-5\n",
        "---\n",
        "\n",
        "LeNet-5[(논문)](http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf) 구조는 아마도 가장 널리 알려진 CNN 구조일 것입니다. 이 구조는 1998년 얀 르쿤이 만들었으며 손글씨 숫자 인식(MNIST)에 널리 사용되었습니다. \n",
        "\n",
        "\n",
        "![](https://www.datasciencecentral.com/wp-content/uploads/2021/10/1lvvWF48t7cyRWqct13eU0w.jpeg)"
      ],
      "metadata": {
        "id": "smec5PcVY_iZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### | LeNet-5을 이용한 손글씨 이미지 분류"
      ],
      "metadata": {
        "id": "H5gXVz4_jTyl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####  **데이터 준비**"
      ],
      "metadata": {
        "id": "9XFyQs_Nm6w0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "# 전처리-정규화\n",
        "x_train, x_test = x_train/255.0, x_test/255.\n",
        "# 전처리-shape 맞추기\n",
        "x_train = np.expand_dims(x_train,3)\n",
        "x_test = np.expand_dims(x_test,3)\n",
        "\n",
        "print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)"
      ],
      "metadata": {
        "id": "eFbUg6pkhV0I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40c4ebfd-f7ef-4ff7-d709-5a1447d27367"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n",
            "(60000, 28, 28, 1) (10000, 28, 28, 1) (60000,) (10000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **모델 구성**"
      ],
      "metadata": {
        "id": "OsX9GfKbiKRy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers, models, utils\n",
        "def build_lenet5():\n",
        "    x = layers.Input(shape=(28,28,1))\n",
        "    y = layers.Conv2D(filters=6, kernel_size=5, padding='same', activation='tanh')(x)\n",
        "    y = layers.AvgPool2D(pool_size=2, strides=2)(y)\n",
        "    y = layers.Conv2D(filters=16, kernel_size=5, padding='valid', activation='tanh')(y)\n",
        "    y = layers.MaxPool2D(pool_size=2, strides=2)(y)\n",
        "\n",
        "    y = layers.Flatten()(y)\n",
        "    y = layers.Dense(120, activation='tanh')(y)\n",
        "    y = layers.Dense(84, activation='tanh')(y)\n",
        "    y = layers.Dense(10, activation='softmax')(y)\n",
        "    model = tf.keras.models.Model(x,y)\n",
        "    return model\n",
        "\n",
        "model = build_lenet5()\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "6M3wFU_lZFoV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0629deed-547c-44af-9b43-facc3f694932"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 28, 28, 6)         156       \n",
            "                                                                 \n",
            " average_pooling2d_1 (Averag  (None, 14, 14, 6)        0         \n",
            " ePooling2D)                                                     \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 10, 10, 16)        2416      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 5, 5, 16)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 400)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 120)               48120     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 84)                10164     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 10)                850       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 61,706\n",
            "Trainable params: 61,706\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **학습 및 평가**"
      ],
      "metadata": {
        "id": "rz5mqFWCiLiv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_lenet5()\n",
        "model.summary()\n",
        "model.compile(optimizer='sgd', # 경사하강법 (배치개수에 한번씩 업데이트)\n",
        "              loss = 'sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.fit(x_train,y_train, epochs=10)\n",
        "print('------------- 테스트 스코어 -----------------')\n",
        "model.evaluate(x_test, y_test)"
      ],
      "metadata": {
        "id": "pKqI02-5aZ1I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b327aae5-b41e-4cfb-8978-fab7c9542055"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 28, 28, 6)         156       \n",
            "                                                                 \n",
            " average_pooling2d_2 (Averag  (None, 14, 14, 6)        0         \n",
            " ePooling2D)                                                     \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 10, 10, 16)        2416      \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 5, 5, 16)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 400)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 120)               48120     \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 84)                10164     \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 10)                850       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 61,706\n",
            "Trainable params: 61,706\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 40s 21ms/step - loss: 0.5523 - accuracy: 0.8540\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 48s 26ms/step - loss: 0.1818 - accuracy: 0.9488\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 39s 21ms/step - loss: 0.1292 - accuracy: 0.9626\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 39s 21ms/step - loss: 0.1030 - accuracy: 0.9702\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 40s 22ms/step - loss: 0.0872 - accuracy: 0.9748\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 39s 21ms/step - loss: 0.0763 - accuracy: 0.9775\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 41s 22ms/step - loss: 0.0684 - accuracy: 0.9796\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 39s 21ms/step - loss: 0.0617 - accuracy: 0.9819\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 40s 21ms/step - loss: 0.0564 - accuracy: 0.9837\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 39s 21ms/step - loss: 0.0522 - accuracy: 0.9850\n",
            "------------- 테스트 스코어 -----------------\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0505 - accuracy: 0.9825\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.05045868828892708, 0.9825000166893005]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **| Feature map**"
      ],
      "metadata": {
        "id": "MDlSRAle6SKL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **feature map 얻기**"
      ],
      "metadata": {
        "id": "Idw3nITWaaGb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "sEFcCb5Btua2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **시각화**\n",
        "\n",
        "![](https://www.datasciencecentral.com/wp-content/uploads/2021/10/1lvvWF48t7cyRWqct13eU0w.jpeg)\n",
        "\n",
        "[시각화 함수 스크립트](https://github.com/yebiny/SkillTreePython-DeepLearning/blob/main/01.%EB%94%A5%EB%9F%AC%EB%8B%9Dwith%ED%85%90%EC%84%9C%ED%94%8C%EB%A1%9C%EC%9A%B0-basic/scripts/featuremap_dict.py)"
      ],
      "metadata": {
        "id": "KS8K45aqWbYb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as numpy\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def show_featuremap(sample_idx, fmaps, cnn_idxs, flatten_idxs):\n",
        "  for idx in cnn_idxs:\n",
        "    fmap = fmaps[idx][sample_idx]\n",
        "    chs = fmap.shape[2]\n",
        "    print(f'{idx} 번째 Convolutional 레이어 {fmap.shape}')\n",
        "    for ch in range(chs):\n",
        "      plt.subplot(1,chs,ch+1)\n",
        "      plt.imshow(fmap[:,:,ch], cmap='gray')\n",
        "      plt.xticks([]);plt.yticks([])\n",
        "    plt.show()\n",
        "\n",
        "  for idx in flatten_idxs:\n",
        "    fmap = fmaps[idx][sample_idx]\n",
        "    print(f'{idx} 번째 Dense 레이어 {fmap.shape}')\n",
        "    plt.figure(figsize=(int(len(fmap)/5),10))\n",
        "    plt.imshow(tf.reshape(fmap,(1,len(fmap))), cmap='gray')\n",
        "    plt.xticks(range(10));plt.yticks([]);plt.show()"
      ],
      "metadata": {
        "id": "lR5o-iP0znfa"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 과제 1. 의류 이미지 분류\n",
        "---\n",
        "* 데이터셋 : f-minst(fashoin mnist)\n",
        "* 데이터를 소개하세요.\n",
        "* 데이터의 형태를 파악하세요\n",
        "* 적절한 모델을 생성하세요\n",
        "* 데이터에 적합하게 학습을 진행하세요."
      ],
      "metadata": {
        "id": "PxzWofuOruDD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# 1. Fashion MNIST 데이터셋 불러오기\n",
        "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()"
      ],
      "metadata": {
        "id": "-9STHCzXruDD"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_images[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F8XoPhXCAUBO",
        "outputId": "8a9430d7-ac28-4d20-b12d-d04db8c05d21"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   1   0   0  13  73   0\n",
            "    0   1   4   0   0   0   0   1   1   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   3   0  36 136 127  62\n",
            "   54   0   0   0   1   3   4   0   0   3]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   6   0 102 204 176 134\n",
            "  144 123  23   0   0   0   0  12  10   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 155 236 207 178\n",
            "  107 156 161 109  64  23  77 130  72  15]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   1   0  69 207 223 218 216\n",
            "  216 163 127 121 122 146 141  88 172  66]\n",
            " [  0   0   0   0   0   0   0   0   0   1   1   1   0 200 232 232 233 229\n",
            "  223 223 215 213 164 127 123 196 229   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0 183 225 216 223 228\n",
            "  235 227 224 222 224 221 223 245 173   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0 193 228 218 213 198\n",
            "  180 212 210 211 213 223 220 243 202   0]\n",
            " [  0   0   0   0   0   0   0   0   0   1   3   0  12 219 220 212 218 192\n",
            "  169 227 208 218 224 212 226 197 209  52]\n",
            " [  0   0   0   0   0   0   0   0   0   0   6   0  99 244 222 220 218 203\n",
            "  198 221 215 213 222 220 245 119 167  56]\n",
            " [  0   0   0   0   0   0   0   0   0   4   0   0  55 236 228 230 228 240\n",
            "  232 213 218 223 234 217 217 209  92   0]\n",
            " [  0   0   1   4   6   7   2   0   0   0   0   0 237 226 217 223 222 219\n",
            "  222 221 216 223 229 215 218 255  77   0]\n",
            " [  0   3   0   0   0   0   0   0   0  62 145 204 228 207 213 221 218 208\n",
            "  211 218 224 223 219 215 224 244 159   0]\n",
            " [  0   0   0   0  18  44  82 107 189 228 220 222 217 226 200 205 211 230\n",
            "  224 234 176 188 250 248 233 238 215   0]\n",
            " [  0  57 187 208 224 221 224 208 204 214 208 209 200 159 245 193 206 223\n",
            "  255 255 221 234 221 211 220 232 246   0]\n",
            " [  3 202 228 224 221 211 211 214 205 205 205 220 240  80 150 255 229 221\n",
            "  188 154 191 210 204 209 222 228 225   0]\n",
            " [ 98 233 198 210 222 229 229 234 249 220 194 215 217 241  65  73 106 117\n",
            "  168 219 221 215 217 223 223 224 229  29]\n",
            " [ 75 204 212 204 193 205 211 225 216 185 197 206 198 213 240 195 227 245\n",
            "  239 223 218 212 209 222 220 221 230  67]\n",
            " [ 48 203 183 194 213 197 185 190 194 192 202 214 219 221 220 236 225 216\n",
            "  199 206 186 181 177 172 181 205 206 115]\n",
            " [  0 122 219 193 179 171 183 196 204 210 213 207 211 210 200 196 194 191\n",
            "  195 191 198 192 176 156 167 177 210  92]\n",
            " [  0   0  74 189 212 191 175 172 175 181 185 188 189 188 193 198 204 209\n",
            "  210 210 211 188 188 194 192 216 170   0]\n",
            " [  2   0   0   0  66 200 222 237 239 242 246 243 244 221 220 193 191 179\n",
            "  182 182 181 176 166 168  99  58   0   0]\n",
            " [  0   0   0   0   0   0   0  40  61  44  72  41  35   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_images[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4bV5wHfOAUEO",
        "outputId": "f64d46cd-1a95-4170-dcbd-d3fec5007bef"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   1   0   0  13  73   0\n",
            "    0   1   4   0   0   0   0   1   1   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   3   0  36 136 127  62\n",
            "   54   0   0   0   1   3   4   0   0   3]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   6   0 102 204 176 134\n",
            "  144 123  23   0   0   0   0  12  10   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 155 236 207 178\n",
            "  107 156 161 109  64  23  77 130  72  15]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   1   0  69 207 223 218 216\n",
            "  216 163 127 121 122 146 141  88 172  66]\n",
            " [  0   0   0   0   0   0   0   0   0   1   1   1   0 200 232 232 233 229\n",
            "  223 223 215 213 164 127 123 196 229   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0 183 225 216 223 228\n",
            "  235 227 224 222 224 221 223 245 173   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0 193 228 218 213 198\n",
            "  180 212 210 211 213 223 220 243 202   0]\n",
            " [  0   0   0   0   0   0   0   0   0   1   3   0  12 219 220 212 218 192\n",
            "  169 227 208 218 224 212 226 197 209  52]\n",
            " [  0   0   0   0   0   0   0   0   0   0   6   0  99 244 222 220 218 203\n",
            "  198 221 215 213 222 220 245 119 167  56]\n",
            " [  0   0   0   0   0   0   0   0   0   4   0   0  55 236 228 230 228 240\n",
            "  232 213 218 223 234 217 217 209  92   0]\n",
            " [  0   0   1   4   6   7   2   0   0   0   0   0 237 226 217 223 222 219\n",
            "  222 221 216 223 229 215 218 255  77   0]\n",
            " [  0   3   0   0   0   0   0   0   0  62 145 204 228 207 213 221 218 208\n",
            "  211 218 224 223 219 215 224 244 159   0]\n",
            " [  0   0   0   0  18  44  82 107 189 228 220 222 217 226 200 205 211 230\n",
            "  224 234 176 188 250 248 233 238 215   0]\n",
            " [  0  57 187 208 224 221 224 208 204 214 208 209 200 159 245 193 206 223\n",
            "  255 255 221 234 221 211 220 232 246   0]\n",
            " [  3 202 228 224 221 211 211 214 205 205 205 220 240  80 150 255 229 221\n",
            "  188 154 191 210 204 209 222 228 225   0]\n",
            " [ 98 233 198 210 222 229 229 234 249 220 194 215 217 241  65  73 106 117\n",
            "  168 219 221 215 217 223 223 224 229  29]\n",
            " [ 75 204 212 204 193 205 211 225 216 185 197 206 198 213 240 195 227 245\n",
            "  239 223 218 212 209 222 220 221 230  67]\n",
            " [ 48 203 183 194 213 197 185 190 194 192 202 214 219 221 220 236 225 216\n",
            "  199 206 186 181 177 172 181 205 206 115]\n",
            " [  0 122 219 193 179 171 183 196 204 210 213 207 211 210 200 196 194 191\n",
            "  195 191 198 192 176 156 167 177 210  92]\n",
            " [  0   0  74 189 212 191 175 172 175 181 185 188 189 188 193 198 204 209\n",
            "  210 210 211 188 188 194 192 216 170   0]\n",
            " [  2   0   0   0  66 200 222 237 239 242 246 243 244 221 220 193 191 179\n",
            "  182 182 181 176 166 168  99  58   0   0]\n",
            " [  0   0   0   0   0   0   0  40  61  44  72  41  35   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_images.shape)\n",
        "print(train_labels.shape)\n",
        "print(test_images.shape)\n",
        "print(test_labels.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z36ZOy9kAUG-",
        "outputId": "9c0dfebe-8cba-49fc-efc6-82fe33082094"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28)\n",
            "(60000,)\n",
            "(10000, 28, 28)\n",
            "(10000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. 데이터 전처리\n",
        "train_images, test_images = train_images / 255.0, test_images / 255.0"
      ],
      "metadata": {
        "id": "_lGJ01h8AUM-"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. 모델 구성\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dense(256, activation='tanh'),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(64, activation='tanh'),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "tBZ3X8s9AnAW"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. 모델 컴파일\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "UEt4zWpVAnDH"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. 모델 훈련\n",
        "model.fit(train_images, train_labels, epochs=15)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ASN6EgXhAnFV",
        "outputId": "f3e0fba0-c2bc-4151-e98b-b8e15f3d7544"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "1875/1875 [==============================] - 20s 10ms/step - loss: 0.4799 - accuracy: 0.8256\n",
            "Epoch 2/15\n",
            "1875/1875 [==============================] - 18s 10ms/step - loss: 0.3707 - accuracy: 0.8640\n",
            "Epoch 3/15\n",
            "1875/1875 [==============================] - 18s 10ms/step - loss: 0.3377 - accuracy: 0.8765\n",
            "Epoch 4/15\n",
            "1875/1875 [==============================] - 18s 9ms/step - loss: 0.3183 - accuracy: 0.8822\n",
            "Epoch 5/15\n",
            "1875/1875 [==============================] - 18s 10ms/step - loss: 0.3000 - accuracy: 0.8902\n",
            "Epoch 6/15\n",
            "1875/1875 [==============================] - 17s 9ms/step - loss: 0.2888 - accuracy: 0.8934\n",
            "Epoch 7/15\n",
            "1875/1875 [==============================] - 17s 9ms/step - loss: 0.2738 - accuracy: 0.8988\n",
            "Epoch 8/15\n",
            "1875/1875 [==============================] - 17s 9ms/step - loss: 0.2697 - accuracy: 0.9005\n",
            "Epoch 9/15\n",
            "1875/1875 [==============================] - 18s 9ms/step - loss: 0.2590 - accuracy: 0.9035\n",
            "Epoch 10/15\n",
            "1875/1875 [==============================] - 19s 10ms/step - loss: 0.2543 - accuracy: 0.9052\n",
            "Epoch 11/15\n",
            "1875/1875 [==============================] - 18s 9ms/step - loss: 0.2478 - accuracy: 0.9076\n",
            "Epoch 12/15\n",
            "1875/1875 [==============================] - 17s 9ms/step - loss: 0.2416 - accuracy: 0.9097\n",
            "Epoch 13/15\n",
            "1875/1875 [==============================] - 17s 9ms/step - loss: 0.2361 - accuracy: 0.9124\n",
            "Epoch 14/15\n",
            "1875/1875 [==============================] - 17s 9ms/step - loss: 0.2335 - accuracy: 0.9124\n",
            "Epoch 15/15\n",
            "1875/1875 [==============================] - 18s 9ms/step - loss: 0.2283 - accuracy: 0.9155\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb4b36df410>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. 정확도 평가하기\n",
        "loss, accuracy = model.evaluate(test_images, test_labels)\n",
        "print(loss, accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "omu3YuyJAnIW",
        "outputId": "0b7e55bf-ba1b-4600-b5fa-24d7a1812e3c"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 2s 5ms/step - loss: 0.3941 - accuracy: 0.8916\n",
            "0.3941105902194977 0.8916000127792358\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. 예측하기\n",
        "predictions = model.predict(test_images)\n",
        "print(predictions[0])\n",
        "print(np.argmax(predictions[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dhlIYtykAnKe",
        "outputId": "1726bb63-5e08-438f-d5b9-549f3cc662a7"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1.5095196e-12 2.8791815e-14 7.6481252e-16 3.6358553e-20 3.9419838e-15\n",
            " 6.5939598e-06 8.0985218e-15 1.5799227e-03 2.9248681e-14 9.9841344e-01]\n",
            "9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. 모델 구성\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),      ## CASE 1\n",
        "    # tf.keras.layers.Dense(512, activation='relu'),    ## CASE 2\n",
        "    # tf.keras.layers.Dense(1024, activation='relu'),   ## CASE 3\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "S9eN8WW4AnNR"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. 모델 컴파일\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "t5ILIuWpAnQE"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. 모델 훈련\n",
        "model.fit(train_images, train_labels, epochs=15)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Fzq9wEEAnSq",
        "outputId": "b3c1d08e-47c2-43ab-82d0-7ecce35612b2"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.4984 - accuracy: 0.8250\n",
            "Epoch 2/15\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3738 - accuracy: 0.8657\n",
            "Epoch 3/15\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3374 - accuracy: 0.8775\n",
            "Epoch 4/15\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3119 - accuracy: 0.8856\n",
            "Epoch 5/15\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2959 - accuracy: 0.8909\n",
            "Epoch 6/15\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2804 - accuracy: 0.8962\n",
            "Epoch 7/15\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2672 - accuracy: 0.9009\n",
            "Epoch 8/15\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2556 - accuracy: 0.9049\n",
            "Epoch 9/15\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2485 - accuracy: 0.9070\n",
            "Epoch 10/15\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2384 - accuracy: 0.9107\n",
            "Epoch 11/15\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2301 - accuracy: 0.9140\n",
            "Epoch 12/15\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2233 - accuracy: 0.9152\n",
            "Epoch 13/15\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2164 - accuracy: 0.9187\n",
            "Epoch 14/15\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2117 - accuracy: 0.9208\n",
            "Epoch 15/15\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2044 - accuracy: 0.9235\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb4b371e0d0>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 과제 2. 동물 및 물체 이미지 분류\n",
        "---\n",
        "* 데이터셋 : cifar-10\n",
        "* 데이터의 형태를 파악하세요\n",
        "* 적절한 모델을 생성하세요\n",
        "* 데이터를 학습하세요."
      ],
      "metadata": {
        "id": "rxucnPkXrj9D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import datasets, layers, models\n",
        " \n",
        "# 라이브러리 사용\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "\n",
        "cifar10 = datasets.cifar10 \n",
        "(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\n",
        " \n",
        "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
        " \n",
        "print(\"Train samples:\", train_images.shape, train_labels.shape)\n",
        "print(\"Test samples:\", test_images.shape, test_labels.shape)\n",
        " \n",
        "train_images = train_images.reshape((50000, 32, 32, 3))\n",
        "test_images = test_images.reshape((10000, 32, 32, 3))\n",
        "\n",
        "\n",
        "\n",
        "# 모델 구성\n",
        "def build_lenet():\n",
        "    x = layers.Input(shape=(32,32,3))\n",
        "    y = layers.Conv2D(6, kernel_size=5, padding='same',activation='tanh')(x)\n",
        "    y = layers.AvgPool2D(pool_size=2, strides=2)(y)\n",
        "    y = layers.Conv2D(filters=16, kernel_size=5, padding='valid', activation='tanh')(y)\n",
        "    y = layers.MaxPool2D(pool_size=2, strides=2)(y)\n",
        "\n",
        "    y = layers.Flatten()(y)\n",
        "    y = layers.Dense(120, activation='tanh')(y)\n",
        "    y = layers.Dense(84, activation='tanh')(y)\n",
        "    y = layers.Dense(10, activation='softmax')(y)\n",
        "    model = tf.keras.models.Model(x, y)\n",
        "    return model\n",
        "\n",
        "model = build_lenet()\n",
        "model.summary()\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.fit(train_images, train_labels, epochs=10)\n",
        " \n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        " \n",
        "print('Test accuracy:', test_acc)\n",
        " \n",
        "predictions = model.predict(test_images)\n",
        " \n",
        "def plot_image(i, predictions_array, true_label, img):\n",
        "  predictions_array, true_label, img = predictions_array[i], true_label[i], img[i]\n",
        "  plt.grid(False)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        " \n",
        "  plt.imshow(img, cmap=plt.cm.binary)\n",
        " \n",
        "  predicted_label = np.argmax(predictions_array)\n",
        "  if predicted_label == true_label:\n",
        "    color = 'blue'\n",
        "  else:\n",
        "    color = 'red'\n",
        " \n",
        "  plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n",
        "                                100*np.max(predictions_array),\n",
        "                                class_names[true_label[0]]),\n",
        "                                color=color)\n",
        " \n",
        "def plot_value_array(i, predictions_array, true_label):\n",
        "  predictions_array, true_label = predictions_array[i], true_label[i]\n",
        "  plt.grid(False)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "  thisplot = plt.bar(range(10), predictions_array, color=\"#777777\")\n",
        "  plt.ylim([0, 1])\n",
        "  predicted_label = np.argmax(predictions_array)\n",
        " \n",
        "  thisplot[predicted_label].set_color('red')\n",
        "  thisplot[true_label[0]].set_color('blue')\n",
        " \n",
        "i = 0\n",
        "plt.figure(figsize=(6,3))\n",
        "plt.subplot(1,2,1)\n",
        "plot_image(i, predictions, test_labels, test_images)\n",
        "plt.subplot(1,2,2)\n",
        "plot_value_array(i, predictions,  test_labels)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ck-A9LrDrj9D",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "61452eea-edd6-40b0-cdd2-526e9dae2b61"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train samples: (50000, 32, 32, 3) (50000, 1)\n",
            "Test samples: (10000, 32, 32, 3) (10000, 1)\n",
            "Model: \"model_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_8 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
            "                                                                 \n",
            " conv2d_13 (Conv2D)          (None, 32, 32, 6)         456       \n",
            "                                                                 \n",
            " average_pooling2d_3 (Averag  (None, 16, 16, 6)        0         \n",
            " ePooling2D)                                                     \n",
            "                                                                 \n",
            " conv2d_14 (Conv2D)          (None, 12, 12, 16)        2416      \n",
            "                                                                 \n",
            " max_pooling2d_7 (MaxPooling  (None, 6, 6, 16)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_9 (Flatten)         (None, 576)               0         \n",
            "                                                                 \n",
            " dense_25 (Dense)            (None, 120)               69240     \n",
            "                                                                 \n",
            " dense_26 (Dense)            (None, 84)                10164     \n",
            "                                                                 \n",
            " dense_27 (Dense)            (None, 10)                850       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 83,126\n",
            "Trainable params: 83,126\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1563/1563 [==============================] - 59s 37ms/step - loss: 1.6787 - accuracy: 0.3975\n",
            "Epoch 2/10\n",
            "1563/1563 [==============================] - 58s 37ms/step - loss: 1.3980 - accuracy: 0.5037\n",
            "Epoch 3/10\n",
            "1563/1563 [==============================] - 57s 36ms/step - loss: 1.2851 - accuracy: 0.5462\n",
            "Epoch 4/10\n",
            "1563/1563 [==============================] - 55s 35ms/step - loss: 1.2088 - accuracy: 0.5727\n",
            "Epoch 5/10\n",
            "1563/1563 [==============================] - 57s 36ms/step - loss: 1.1527 - accuracy: 0.5927\n",
            "Epoch 6/10\n",
            "1563/1563 [==============================] - 55s 35ms/step - loss: 1.1088 - accuracy: 0.6108\n",
            "Epoch 7/10\n",
            "1563/1563 [==============================] - 55s 35ms/step - loss: 1.0615 - accuracy: 0.6267\n",
            "Epoch 8/10\n",
            "1563/1563 [==============================] - 55s 35ms/step - loss: 1.0328 - accuracy: 0.6355\n",
            "Epoch 9/10\n",
            "1563/1563 [==============================] - 56s 36ms/step - loss: 0.9914 - accuracy: 0.6501\n",
            "Epoch 10/10\n",
            "1563/1563 [==============================] - 55s 35ms/step - loss: 0.9577 - accuracy: 0.6617\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 1.2721 - accuracy: 0.5615\n",
            "Test accuracy: 0.5615000128746033\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x216 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWAAAAC6CAYAAACQs5exAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAbt0lEQVR4nO3deZBlVX0H8O+5923d/Xqd7umehVkYhkUxQUAS3AA1FaMhwQqpuERiWalKxSTGpDSFFRITq5Ii5T/6R9QyBLGM0ViUSCJouZWgAsIwrMM6zAKz9nT39Pb2d+/JH/1w+tzvGWYeOp6h5/upouz76/Puu+92e/rN+b3f7xhrLURE5FcvCn0BIiJnKk3AIiKBaAIWEQlEE7CISCCagEVEAtEELCISSC70BYiENjo6ajdt2hT6MmSFevDBB6estWO+72kCljPepk2bsG3bttCXISuUMWbv8b6nJQgRkUA0AYuIBKIJWEQkEE3AIiKBdJWE6+/J2VUDBSdmPOOM8UVdviZAFhyjc3l6B3kf53tSX9Bm/wb5rsF3fs/JMuN8fY5OvvkRnz/7SGtPfJ+XHndy9yfNXttJnt93z7KR1POys883V2mj1khO9klFXvG6moBXDRTwifee78SMTWlcIe+e1kT8RrvZbFCsnbT4XAV3wk9Sfj7r+X+3iRKKRTGFYFt97uPAj8sX6hSLPbfORO51JGmbxrTafP1p6pvM+fztzNzU8DzOP7Hyc/r+SDab7v1PEs9r9Jwr8tyzZubnVOFbgWrTfdyXv7+fB4msYFqCEBEJRBOwiEggXS1BWBg0M3O2tTUemPnnZxF9NCQCrwfkcp5lgxMv0cLk+e9Io9mkWDv1PGdmDTj2LFPkPH+mTMrLJWi7yyq+f5qnnmtomhLFkrjI4zKPbSZ8YSbl5zSepZCS557ljBuLcnyzk5bndRs+v828dutZHIlj9/m0+CtnGr0DFhEJRBOwiEggmoBFRALRBCwiEkiX3dAsbDahY/nzvDZxx5iEE09pi5NkcY8nqQQ3oedLkqWexFMhn6dY23Isbbkn9J2r3fYktjwFFVEmoWfiAo2xMSfcagkn3A5Nc7Kr0nSfc3GRx8SWr7W/xDetYPjzvAO9Pc5xT5GTa2nEP7fIm2Bzn5PvPNDKfn5bWTg5w+gdsIhIIJqARUQC0QQsIhJIV2vAxlrkksyab+xZC80UKRRjTyOAnGfBz9MzIsp8WN9XiNH2dXqJ+Pz5Qg/FJjad6xzPz07RmKnpKp8rx+u7Edy13Gabb2/N8jU8uZef0xZHKNaK3YKWZpnXkxfnZii2f3KWYuUiX1tyyB23YZxf46p+Xq8u5Xw9I9yfecHz404y69Un08RJZCXRO2ARkUA0AYuIBKIJWEQkEE3AIiKBvIxt6d1EickN8YhMMqXta+IdcWKu2eYP+RcyXcGShAsNrKd4Ap6ETsHTAew33vZbzvGD99xLYw7MTlOs4kmwtRM3SbZ33xEas3s/Nx0vDq2h2PrxzRSzxX7nuJnjhFi+PMbXVV+k2PTkAYr1DrmJv32Lh2lM3dMQf7yfyyx6824hRtLiRGaUrcM42c1CRFYIvQMWEQlEE7CISCCagEVEAtEELCISSFdJuNREaERuImiu2kvjkszWPMNlTrgNxJw4y3k6jKWZxJwvUUMd2uCpoANQrR6l2A+/dbtzfHiWu7sdXuRz7d3P59p78AXnOC6VaUwSD1Csb2CUYvlefmyu5FbRFQ1fVyni7Z+mmrxt1Jr1GyhWr1Wc4927OQk3M+fZIdrwtW4ac2P5xLMzc7Zrnirh5Ayjd8AiIoFoAhYRCUQTsIhIIJqARUQC6SoJ104NjtTcCqeZFlfC3X3PXc7xBVs5MXTVqznxNOxpbZlmKt8iz55EUcSVWInl7Xo8OSvs3rvbOZ6pcXWZ7R2mWFzmxFM0vOAc9wwN0phmnZNYTd/2QMN8zwbKbmzy0CEaM3+U21H2F/jHXOrhtpjPH3XbYub7V9OYI4eep1j58ALFJgYy2xsZT+Vgpm0pPElYkZVM74BFRALRBCwiEogmYBGRQLrbkiguIjfodumqTvMc3iq4HblmqrxuW23ydjoDBe6Glma2toFn+6E45mKQepPXOI9wjQWmFtw15mxHMAAYHuOihUo6T7FRuM8Zl/gamnl+jfUKr6HWF/n8G8dXOcdVz9rupKfowuR5XXtuhruTIdNVrlap0JC4wPd6cp6LUg5mCjY2jnrW7rNL36rDkDOM3gGLiASiCVhEJBBNwCIigWgCFhEJpKskXKmnD+f92mVObN99T9O48qCbhLvs8stoTG+8l2JNTzIqyrlFFibPia3EcjFI/+qzKPbwozv5WofcxNa6ja+mMTbybP3jSaalDXfrombTsxVTjotGYk+Rwo5HHqXYQNF9bG8fF2v0ebqoHTjEXc3avmRmJlk33M/3ei7hApejMxzbfWjOOV47PkFjctmkq69SRmQF02+8iEggmoBFRALRBCwiEogmYBGRQLpKwkVxDr2DbtJq49nn0rhaJiezYfM5NGa0xUmg2d2cmGtlKuGSNldiXfbmayi24exLKbb5NXso9uBDjzjHw2VOFh2YnKJYzhYoVsxnEmye5l6LnuqyOU8Hs+E+TtZlT5d4EmmjY2MUa7R4y6apo3MUM5ltnPrLnOTLxfwr06xzVd2uF/Y5x2NDnNDbut7d3srq/YCcYfQbLyISiCZgEZFANAGLiASiCVhEJJDu2lFGEeKiW2l14PCTNO6iS17nHPcNcuIsXthPsaTNSaVcpuXirhe4Wu6Nw5spht71FOrv42RRKee+nh5Pu8VSgSvhsq0bAWDd2jXO8RPPPUdjCgVuwzm/wK9p0/qtFDv3/Fc5xzMz3AayPMBVgQcOTVLMRNwecmjYbcU552kzGcf8N7unl5+ztuDe652en1tPwT1Xq82VgyIrmd4Bi4gEoglYRCQQTcAiIoFoAhYRCaS7JJyJkS8NOLF6ndsyNhpuKVzek9jq7RugWJ9nD7Vi7FZxlXO8sdstX/hPil39R39JsXzlEMUKRfdvUBRx1djms9dRbHLmAMXqi26V28TqURozM8+JwEaT7+HZ53D14JZz3KrDuYe205jKwiLF5iv8nO2EE161mruP29DQII1JLCfTBoa4aq/ddO9jHPHPbd9BNznY9FTsiaxkegcsIhKIJmARkUA0AYuIBNLVGjCMgYnd9b7qInf3qldrznE+z4UMC9NcyICY14DzcLt2rRniAoJnn+Sthg7s4xiqvG67d98e5/i1E7x90rqN3CFt7eQ4xSo73W5uI0XPVklDvC68a9ceiq1Zy+vOs/PzznHLs457+Mg0xVJrKGY8Xc2qmTVgE/HPiM8E9Hm6piF1izoKpkZDmtPumrz1tY8TWcH0DlhEJBBNwCIigWgCFhEJRBOwiEgg3SXhLIDMNjix5UTQmlF326LeEifhfvgodwob9nTD2jriJv1KRU4MFXJ1ih2Z3EOxtMHdvTZscTupxZ5r7R0YptjoOHdbm55xiyDmPEUXiSf3OObZRijnSVzWM8UNvsKFWp0LHtqeJ/XF6g23IKTd5r/Pq0ZXU8wYLsQoGPdnUjR8rYl1C3Tynk5rIiuZfuNFRALRBCwiEogmYBGRQDQBi4gE0mU3NCCfcyvRBstcvTbU78ZMygmYecvVU1NHuc5qtN+9xL4CJ3ySqEWxPQf2UGx8mLt7bTzH3eanzqfC/Q/ytkv7D3JCr7/sJuvyed5+aMfO5/kJPH8HU0+skUnCLVa4umxoZIRibU8l3MHDvE1RX797f3IxV6b19nJnu4Jvy6aWW5GXVGZpyPjqfvf58lzlKLKS6R2wiEggmoBFRALRBCwiEogmYBGRQLqrhAMQGzehM7GaWzXmMvN66qnOWrN+M8W2eRJns8ZN1tmY218OjnJV1+AAJ+vypX6Kbcok4cqDq2jMF2/+MsWqntc0X5txx9T4WvOeOz4xzNdan9lLsUqmCnBwgBOZTz39LMUOHz7C1+rZumhoyL24gb4yjYktZynzTX6dcab151gfP26w5P4u5fR2QM4w+pUXEQlEE7CISCCagEVEAulqDTiKIvrQ/cAwrwG3E/e0xRx/UP/czRsotu1BXqOdz7vbs6eGt0UfX8drqE88eR/FXn/FByh27z3uuEplnsa0mlMUmzz0AsWyf88WW/z3LQdeCx2OuKhjXQ9fx9wRd323HXOXtvHVHEsST9e0GneQq9fc7m0VT0e2dsprx636foqtzrtFImvLXMDRaLtj9G5AzjT6nRcRCUQTsIhIIJqARUQC0QQsIhJI10m4vrL74f/h0VEa1zbuaetRgcaUygMUGxribmXPv3DIOX7j615NY+qLvJVRbz8XHxzcv49iO595xjluJ00aE3madFXm5yjWv2qNczw3x1sSDZa5Q9p5515IsQceeYpi25/a4xy/8crfoTH5Aie7du3cSbG5Bb62bAe2eo0TbhvHOVHa08cd8UZG3HE2x4nAdtPttmYNd20TWcn0DlhEJBBNwCIigWgCFhEJRBOwiEggXSXhrE2Rtt3kzeAId8yq1NyuXdWEt7aJY577N5y1nmLP7HCrv+aqnHAr93FV3VlbKIS9z3CHsf0HDjrHl1/+OhpTrXIyqn/tOoqNrHU7vD0/w4m0WoOvv9DH2wgNjJ1Fsdf2u/fnyJFpGrNn7yMUq9Q4sTg7x69pbGzMOR60B2nMxjKfa/UAZynzxq3ka7Z4+6S+TNItAv+eiKxkegcsIhKIJmARkUA0AYuIBKIJWEQkkK6ScGm7hYVpNzHT42lZ2Ki7iRqT8tMYwwmX0RHeDuiZaJdzPDnD299Mx5zYGixzm8zzL+RKu1173baSLd7dCLPzXDW2detWjm12M397D3K13I4dj1Fseoqr1wpFTm4Ol93qsn07OMl3aJrbWBpPJWLs2Z4pu03URk9h2oZ+ruQrRVzl1qi7P5M05ZahrXbmccrByRlG74BFRALRBCwiEogmYBGRQDQBi4gE0lUSrtFoYNdONym2YesFNK4UuUm4tMlVULmSJ5njifX3u8mo8gC3sTz//PMo9v3v3kmx6twhivWOrHaOd+6bpDFnredKu83nXUyxYsG9nWdv4MfNzvD+b088+SzFUsvZwP2z7n2dr/GYesJJ0flZTiKunuCqw+en3XEjZ3HScrrI50fqqbRru9dmc/yzbWQe14Sn76fICqZ3wCIigWgCFhEJRBOwiEggXa0BVxttPLzTXSPdcOFlNC6FWyxhsh+4B4CUP3U/v7BAsdnZKed41chFNOYdb7+KYhf9+vkU+/o3bqOYMe664+DgMI1Zt5bXS8sDQxSL2+7rHpng27tmc4ticz28PvrQI9zV7OCiWxlh87wePjjBxSyjW3gtN/asySbWPf/Tto/G7DzE686FmCs2avW6c1z1/Aq0U/feLyRcWCKykukdsIhIIJqARUQC0QQsIhKIJmARkUC6SsLVE4Nn5nqc2FTCXbVs3k3ARE3uCmZT/tB9FHFs7Rq3UOJNr+cCiFKeE0ObN/KWQe+89t0Uu/W2O5zjqUN8rQfnuNtavb6TYgW4maaZGmeedu7lYhA0OTFnR7m4ZHi12zUt9bQPM4a7jqUl7raWGu6Q1spsHTWX8LlKeX5cKcdJuIpxizpaeT6XTd3XnRgVYsiZRe+ARUQC0QQsIhKIJmARkUA0AYuIBNJdN7TE4JlZd86+/Se8xc5FG0ed44kCV1T15j1VYhO8jdCaUbfaa8vZXJUGy924Dh6ZptjNX7uDYtsffsI5zm6nBAC+Qj5Y/ttlE/exSZEr1ZKIk1E59FCs7UlItSN3XMn307OcEKs3Pdca8bhcpjouTjn5aOt8M9rgcfnUfc7Y8DU0W+41eHapElnR9A5YRCQQTcAiIoFoAhYRCUQTsIhIIF0l4RIYLEZuJdQPtj9D4559zt226O2XvIrGbFnLLRJ37+Kted78ugud45KnomqhyQmrr3/nAYo99MQBilXbmS12PG0aozz/nUo97TQj4yaofImuJOWqvUbK528lPM4Yt3KsAU91meXryuX4/HHMsd5e92dbAF9Dwvk2JIZ/jZLMwHaLk3eFfrelp4m6+nU8vU1MAIcPn/z48XHgkKdKUlY0vQMWORW6mXxfznhZETQBi4gEoglYRCQQTcAiIoF0lfXI5XJYNTrmxGaOctLn4NFZ5/ieR3ivr6S10fMM3OpwbMKtfDNxkcbcv+1xit3xw3sp1ki5LSNy7vmi6OT+JiUNrpizmcRc6km4+ZJk2b3YACCf4x+NiTPJxpjvVy47BkAc87n6+8s8LvPaI8ttMhNPBWDqSQZms3UTE5x07R9wY88V+fWIrGR6BywiEogmYBGRQDQBi4gE0tUasDGG1hjzeV6Tbdfdtbw9h+dpTKPyJMXefPG5FOsZWuMcz9W5EuCun22jWN3yB/9bbV7TLBbdwovU0wGsWq1SzCfOFCQYXtqFZxchFD1rtN6ihEzMFHlNu6eHO6vlPOvJLU9hxEKl4hwnnmKTRpvvz+DwKMXG17ixsqd1W21hwTm2nnsv8ou6/vrrT3rsjTfeeAqvhOkdsIhIIJqARUQC0QQsIhKIJmARkUC6az9lLdJ2prjA98H82E1sNcHFAZOLDYptf5q7lb2j6iaCFuwCjdl/lGPFMhcatKt8HfWGex29vZ4klmf7pOzjAMBE7vkjz7ZCvgIL60m4Wc/fxnwmYbjY4kKPZrtCMV9izlcQkk2wVTzbM5WHOOE2NMZbSTXb7mOffoqLcfKZQpVWk59PZCXTO2ARkUA0AYuIBKIJWGSFmJhY+uz5yfzn2YBcAtAELLJCdNPTXf3fTw9dJuEAZKujLFcvxbHbHSu1nIxKIu6gtWeSk2k3f/1O5/gtV15KY3YfOEKxauLr2uVJbJXcqr24wB25ej3b9xR6eOui2oKbAPNVm1lPJVneUyUW5/ieZc8Xezqf+bZKqlUXT2pc9nxDwyM0ZtX4GopNTc9QbHbK3V5n9nnebuqczZvdgCcxKBJKNxV0wMurotM7YBGRQDQBi4gEoglYRCQQTcAiIoF0lYSLczFGhoacWL3OibNKza1oKsRcidX2JKMiT2vLu+9/1DnefYCr5eYq3GZyZrHGz+kptOrrcyvm2p6WiMUiX1fOk6wr9biVXXHESbJcnh+XeP4Otj1JMpOJWcuVcEmL70WzxS+8p8RJxNFVq5zj4VFOuDU9lY+NgqfVZGZ7oTTHSddK3f0ZpZ6ErshKpnfAIiKBaAIWEQlEE7CISCBdrQHb1KKRWbcreqbwRuKuQ+Y926e3eXkU1rMlfNTjrtHu9RRdRJ6ihXaL11B96871et05rlS4m5hvq3rfunBfwV3n7PEUa0QRX0OhxOfq6eVubs2mW4gxNcMFECm4+COX5+sfHuij2PiIu74/McGFGLMV7gK3MHuUYotzs87x0Aifa+rIlHPc9hSuiKxkegcsIhKIJmARkUA0AYuIBKIJWEQkkK6ScGmaolFzk1bF2NC43sxZ0xYXRXh260EKTlBlP5yferY3ajc54WYTvi7fNjzZWOopxPAl4Y4e5cTTTOZ1DpQ50TXo6TA24Om2VgIn8JLUTYDlDBdixEW+P406J86KOb4/2fO1q3M0pl3lcy3OTlMszRR/lIpciFHPdnMzfE1y6nXT9evldPyS49M7YBGRQDQBi4gE0l1DdpEzzK+iKXfI55Ow9A5YRCSQrt4BV4/smbr/3z+w91RdzErDdWpyAhtDX4Ccekr6HdNdKbK1Y6fqQkREzjRaAxaRl0XvZH9xmoBF5BVhJU74r9wknDHXwJhXneLn2ARjHj/O9276+fMbswfGjHZx3q/AmKdhzOMw5mYYk+/EPwZjHu789ziMSWDMCIwZgzE/6cSuWXae22HM2pd4no/AmOtO+rqOPW4Ixnxo2fEYjPlO1+cRkZdkfNVhrwjG3ALgW7D21lP4HJs6z3HhCcbtAXAprJ16yXHHxr8DwLc7R/8N4G5Y+7nMmKsB/A2sfQuM+TCWcnrfAHAnrL2y8/1LYO0/Hec5cgC2A7gY1nbX59H3uo35IoCbYO1PuzrXK4Ax5ggAJZflVNl4vPzZ6bMEYcw3AZwFoATgM7D2C534Iqwtd76+FsDvAvgCgN8DcAWMuQHAHwDoB/B5AL0AngPwQVh7FMb8CMBDAN4EoA/AdQA+DuA1AP4H1t7QOfffAvhg52pugrWf7nydgzFfAXAxgB0AroO11c55Pwprt2Vexx8D+DCAAoCfAfgQbd5m7Z3Lxt8PYL3njrwHwFc7X7c6r6sIIOlMrh8BcLX/ZgIA3gJg+88nX2PO6dyfMQAJgD8EcBjA7QCGAeQB3ABrbwdwI4AtMOZhAN+DtR8D8E0A7wOw4iZgJZclGGvt6fEfMNL53x4LPG6BVZ3jxWVjrrXALZ2vb7HAtcu+96gFruh8/UkLfLrz9Y8s8G+dr//aAgcssMYCRQvss8AqC1xigccs0GeBsgV2WOC1FthkAWuBN3Qef7MFPrrsvJd2vt5jgVELXGCB/7NAvhP/rAWue4nXnLfAdgu8KRPvtcDMsnsyaIE7LLDNAm+1wIct8IET3M9/tsBfLTv+mQXe1fm61HmOnAUGOrFRC+y0gOm87scz51tngceC/57oP/23gv47ndaAPwxjHgFwH5beCW896UcaMwhgCNbe1Yl8CcCbl434387/PgZgB6w9CGsbAHZ1nuuNAG6DtRVYu4ilf+q/qfOYF3Dsn93/1Rl7PG8FcAmABzrvHt8K4OyXGP9ZLC0//DgTvxrAT2Ht0keJrZ2Dte+EtZdiaVnhagC3wpj/gDG3wpjLPedeA2Bp+xBj+gGsg7W3dc5Xh7VVAAbAv8KYRwF8H8A6AOPHudZJAMdfbxaRrp0eSxDGXAngbQAux7F/3r/YDmz5IjW3CDs5L7bwSpd9/eLxie5BdpH8pRbNDYAvwdqPn/CKjPkElpYD/szz3Xfj2PJD1j8A+BcsLVH8BMCtWPqD8duZcTWc+H69r3MNl8DaVmct+3iPKXXOKSK/JKfLO+BBAEc7k+/5AH5z2fcOw5gLYEwE4F3L4gtYWvddeocIHIUxL75rfT+Au3DyfgzgGhjTC2P6Os/z4rvSDcveYb4XS5Pe8fwAwLUwZjUAdD7BwNVdxvwplibM98Bm+m0uvZu/Aktrs9nHbQWwHtb+CEtrwimW/iD0eK7lSQDnAACsXQCw7+efoDCmCGN6sXTfJzuT71U4Vol27N4ecy4A/ydCRORlOV0m4O9gKdn1JJYSQPct+971AL4F4B4AB5fFvwbgYzDmIRizBcCfAPhU55/TFwH45Ek/u7XbAdwC4H4sJc5ugrUPdb77NIC/6FzbMIDPec+xdJ4nANwA4Lud6/gelpYCsj6PpX/q39v5yNk/LvveuwB8F9by7qBL73z/vvP1VwH8OYAHAHzGM/bbcJdh3o+lZZ5HsXQvJwB8BcClMOYxLCUnn+q8jmkAP+187O1TncdfBeCO4752EenaK/djaHJixtwG4O9g7bO/hHPdDeD3YS13oheRl0UT8EpmzHkAxmHt3b/gecYAvAHWfvOXcl0iAkATsIhIMKfLGrCIyBlHE7CISCCagEVEAtEELCISiCZgEZFANAGLiATy/37cYSF9yi6BAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}